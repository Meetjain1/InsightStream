{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb948e91",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - EDA Playground\n",
    "\n",
    "This notebook explores the e-commerce customer churn dataset and helps identify patterns and insights for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3606b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to the path\n",
    "sys.path.append('..')\n",
    "# © 2025 Meet Jain | Project created by Meet Jain. Unauthorized copying or reproduction is prohibited.\n",
    "\n",
    "from src.helpers import SAMPLE_DATA_PATH, NUMERIC_COLS, CATEGORICAL_COLS, BINARY_COLS, TARGET_COL\n",
    "from src.data_prep import load_csv, basic_clean, handle_missing\n",
    "from src.eda_utils import create_eda_plots\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41515b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "if os.path.exists(SAMPLE_DATA_PATH):\n",
    "    print(f\"Loading data from {SAMPLE_DATA_PATH}\")\n",
    "    df = pd.read_csv(SAMPLE_DATA_PATH)\n",
    "else:\n",
    "    # If sample data doesn't exist, run the synthetic data generator\n",
    "    print(\"Sample data not found. Running synthetic data generator...\")\n",
    "    !python ../data/generate_synthetic_data.py\n",
    "    df = pd.read_csv(SAMPLE_DATA_PATH)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "# © 2025 Meet Jain | Project created by Meet Jain. Unauthorized copying or reproduction is prohibited.\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data cleaning\n",
    "df_clean = basic_clean(df)\n",
    "\n",
    "# Handle missing values if any\n",
    "df_clean = handle_missing(df_clean)\n",
    "\n",
    "# Verify cleaning\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"Dataset shape: {df_clean.shape}\")\n",
    "print(\"Missing values:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a609c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Numeric columns statistics:\")\n",
    "df_clean[NUMERIC_COLS].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns distribution\n",
    "for col in CATEGORICAL_COLS:\n",
    "    print(f\"\\n{col} distribution:\")\n",
    "    print(df_clean[col].value_counts(normalize=True).round(3) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "churn_counts = df_clean[TARGET_COL].value_counts()\n",
    "churn_pct = df_clean[TARGET_COL].value_counts(normalize=True).round(3) * 100\n",
    "\n",
    "print(\"Churn distribution:\")\n",
    "print(f\"Not churned: {churn_counts[0]} ({churn_pct[0]:.1f}%)\")\n",
    "print(f\"Churned: {churn_counts[1]} ({churn_pct[1]:.1f}%)\")\n",
    "\n",
    "# Plot churn distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x=TARGET_COL, data=df_clean, palette=['#4ECDC4', '#FF6B6B'])\n",
    "\n",
    "# Add percentages on top of bars\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2., height + 20, f'{churn_pct[i]:.1f}%', \n",
    "            ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.title('Customer Churn Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Churn')\n",
    "plt.xticks([0, 1], ['Not Churned (0)', 'Churned (1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23027672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore churn by categorical features\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, col in enumerate(CATEGORICAL_COLS, 1):\n",
    "    plt.subplot(len(CATEGORICAL_COLS), 1, i)\n",
    "    \n",
    "    # Calculate churn rate by category\n",
    "    churn_by_cat = df_clean.groupby(col)[TARGET_COL].mean().sort_values(ascending=False) * 100\n",
    "    \n",
    "    # Plot\n",
    "    ax = sns.barplot(x=churn_by_cat.index, y=churn_by_cat.values, palette='viridis')\n",
    "    \n",
    "    # Add percentages on top of bars\n",
    "    for j, p in enumerate(ax.patches):\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2., height + 1, f'{height:.1f}%', \n",
    "                ha=\"center\", fontsize=10)\n",
    "    \n",
    "    plt.title(f'Churn Rate by {col}')\n",
    "    plt.ylabel('Churn Rate (%)')\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45 if len(churn_by_cat) > 3 else 0)\n",
    "    plt.tight_layout()\n",
    "    # © 2025 Meet Jain | Project created by Meet Jain. Unauthorized copying or reproduction is prohibited.\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbee57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore numeric features distribution by churn\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "for i, col in enumerate(NUMERIC_COLS, 1):\n",
    "    plt.subplot(len(NUMERIC_COLS), 2, i*2-1)\n",
    "    \n",
    "    # Histogram by churn\n",
    "    sns.histplot(data=df_clean, x=col, hue=TARGET_COL, bins=20, alpha=0.6, \n",
    "                 palette=['#4ECDC4', '#FF6B6B'], element=\"step\", multiple=\"layer\")\n",
    "    plt.title(f'Distribution of {col} by Churn')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(col)\n",
    "    plt.legend(['Not Churned', 'Churned'])\n",
    "    \n",
    "    plt.subplot(len(NUMERIC_COLS), 2, i*2)\n",
    "    \n",
    "    # Boxplot by churn\n",
    "    sns.boxplot(data=df_clean, y=col, x=TARGET_COL, palette=['#4ECDC4', '#FF6B6B'])\n",
    "    plt.title(f'Boxplot of {col} by Churn')\n",
    "    plt.ylabel(col)\n",
    "    plt.xlabel('Churn')\n",
    "    plt.xticks([0, 1], ['Not Churned', 'Churned'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_cols = NUMERIC_COLS + BINARY_COLS + [TARGET_COL]\n",
    "corr_matrix = df_clean[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47548f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with churn\n",
    "churn_corr = corr_matrix[TARGET_COL].drop(TARGET_COL).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=churn_corr.values, y=churn_corr.index, palette='viridis')\n",
    "\n",
    "# Add correlation values\n",
    "for i, v in enumerate(churn_corr.values):\n",
    "    ax.text(v + 0.01 if v > 0 else v - 0.06, i, f'{v:.2f}', va='center', fontsize=10)\n",
    "\n",
    "plt.title('Features Correlation with Churn')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Features')\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# © 2025 Meet Jain | Project created by Meet Jain. Unauthorized copying or reproduction is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create days since last purchase buckets\n",
    "bins = [0, 30, 60, 90, np.inf]\n",
    "labels = ['0-30 days', '31-60 days', '61-90 days', 'Over 90 days']\n",
    "df_clean['days_bucket'] = pd.cut(df_clean['days_since_last_purchase'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Calculate churn rate by bucket\n",
    "churn_by_days = df_clean.groupby('days_bucket')[TARGET_COL].mean().sort_values() * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=churn_by_days.index, y=churn_by_days.values, palette='viridis')\n",
    "\n",
    "# Add percentages on top of bars\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2., height + 1, f'{height:.1f}%', \n",
    "            ha=\"center\", fontsize=10)\n",
    "\n",
    "plt.title('Churn Rate by Days Since Last Purchase')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xlabel('Days Since Last Purchase')\n",
    "plt.tight_layout()\n",
    "# © 2025 Meet Jain | Project created by Meet Jain. Unauthorized copying or reproduction is prohibited.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tenure buckets\n",
    "bins = [0, 6, 12, 24, 36, np.inf]\n",
    "labels = ['0-6 months', '7-12 months', '1-2 years', '2-3 years', 'Over 3 years']\n",
    "df_clean['tenure_bucket'] = pd.cut(df_clean['tenure_months'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Calculate churn rate by bucket\n",
    "churn_by_tenure = df_clean.groupby('tenure_bucket')[TARGET_COL].mean().sort_values(ascending=False) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=churn_by_tenure.index, y=churn_by_tenure.values, palette='viridis')\n",
    "\n",
    "# Add percentages on top of bars\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2., height + 1, f'{height:.1f}%', \n",
    "            ha=\"center\", fontsize=10)\n",
    "\n",
    "plt.title('Churn Rate by Tenure')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xlabel('Tenure')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Loyalty vs Complaints colored by churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = sns.scatterplot(data=df_clean, x='loyalty_score', y='complaints', \n",
    "                         hue=TARGET_COL, palette=['#4ECDC4', '#FF6B6B'], alpha=0.7)\n",
    "plt.title('Loyalty Score vs Complaints by Churn Status')\n",
    "plt.xlabel('Loyalty Score')\n",
    "plt.ylabel('Complaints')\n",
    "plt.legend(['Not Churned', 'Churned'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try plotly visualizations\n",
    "try:\n",
    "    # Churn rate by region (interactive)\n",
    "    churn_by_region = df_clean.groupby('region')[TARGET_COL].mean().reset_index()\n",
    "    churn_by_region.columns = ['region', 'churn_rate']\n",
    "    churn_by_region['churn_rate'] = churn_by_region['churn_rate'] * 100\n",
    "    \n",
    "    fig = px.bar(churn_by_region, x='region', y='churn_rate',\n",
    "                 labels={'churn_rate': 'Churn Rate (%)', 'region': 'Region'},\n",
    "                 title='Churn Rate by Region',\n",
    "                 text=churn_by_region['churn_rate'].round(1).astype(str) + '%',\n",
    "                 color='churn_rate',\n",
    "                 color_continuous_scale=['#4ECDC4', '#FFD166', '#FF6B6B'])\n",
    "    \n",
    "    fig.update_layout(width=700, height=500)\n",
    "    fig.show()\n",
    "    \n",
    "    # Loyalty vs Days Since Last Purchase colored by churn\n",
    "    fig = px.scatter(df_clean, x='loyalty_score', y='days_since_last_purchase', \n",
    "                     color=df_clean[TARGET_COL].map({0: 'Not Churned', 1: 'Churned'}),\n",
    "                     color_discrete_map={'Not Churned': '#4ECDC4', 'Churned': '#FF6B6B'},\n",
    "                     title='Loyalty Score vs Days Since Last Purchase',\n",
    "                     labels={'loyalty_score': 'Loyalty Score', \n",
    "                             'days_since_last_purchase': 'Days Since Last Purchase'},\n",
    "                     opacity=0.7)\n",
    "    \n",
    "    fig.update_layout(width=800, height=600)\n",
    "    fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating plotly visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Insights\n",
    "print(\"Key Insights from EDA:\")\n",
    "print(\"---------------------\")\n",
    "\n",
    "# Churn rate\n",
    "print(f\"1. Overall churn rate: {df_clean[TARGET_COL].mean() * 100:.1f}%\")\n",
    "\n",
    "# Most correlated feature\n",
    "top_corr = churn_corr.index[0]\n",
    "top_corr_val = churn_corr.values[0]\n",
    "print(f\"2. Most correlated feature with churn: {top_corr} ({top_corr_val:.2f})\")\n",
    "\n",
    "# Region with highest churn\n",
    "region_churn = df_clean.groupby('region')[TARGET_COL].mean()\n",
    "highest_region = region_churn.idxmax()\n",
    "highest_region_rate = region_churn.max() * 100\n",
    "print(f\"3. Region with highest churn: {highest_region} ({highest_region_rate:.1f}%)\")\n",
    "\n",
    "# Payment type with highest churn\n",
    "payment_churn = df_clean.groupby('payment_type')[TARGET_COL].mean()\n",
    "highest_payment = payment_churn.idxmax()\n",
    "highest_payment_rate = payment_churn.max() * 100\n",
    "print(f\"4. Payment type with highest churn: {highest_payment} ({highest_payment_rate:.1f}%)\")\n",
    "\n",
    "# Days since purchase insight\n",
    "if 'days_bucket' in df_clean.columns:\n",
    "    days_churn = df_clean.groupby('days_bucket')[TARGET_COL].mean()\n",
    "    highest_days = days_churn.idxmax()\n",
    "    highest_days_rate = days_churn.max() * 100\n",
    "    print(f\"5. Days since purchase with highest churn: {highest_days} ({highest_days_rate:.1f}%)\")\n",
    "\n",
    "# Tenure insight\n",
    "if 'tenure_bucket' in df_clean.columns:\n",
    "    tenure_churn = df_clean.groupby('tenure_bucket')[TARGET_COL].mean()\n",
    "    highest_tenure = tenure_churn.idxmax()\n",
    "    highest_tenure_rate = tenure_churn.max() * 100\n",
    "    print(f\"6. Tenure bracket with highest churn: {highest_tenure} ({highest_tenure_rate:.1f}%)\")\n",
    "\n",
    "# Promo users\n",
    "promo_churn = df_clean.groupby('is_promo_user')[TARGET_COL].mean()\n",
    "promo_diff = (promo_churn[1] - promo_churn[0]) * 100\n",
    "print(f\"7. Promo users churn {promo_diff:.1f}% {'more' if promo_diff > 0 else 'less'} than non-promo users\")\n",
    "\n",
    "# Complaints\n",
    "complaints_churn = df_clean.groupby(df_clean['complaints'] > 0)[TARGET_COL].mean()\n",
    "if True in complaints_churn.index:\n",
    "    complaint_diff = (complaints_churn[True] - complaints_churn.get(False, 0)) * 100\n",
    "    print(f\"8. Customers with complaints churn {complaint_diff:.1f}% more than those without\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple human-readable interpretations\n",
    "print(\"Simple Interpretations for Business Team:\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"1. looks like ppl with more days since last purchase are way more likely to leave, not good\")\n",
    "print(\"2. customers with low loyalty scores churn more, need to bump those up somehow\")\n",
    "print(\"3. new customers (under 6 months) churn way more than old ones, maybe our onboarding sucks?\")\n",
    "print(f\"4. {highest_payment} users leave more often, wonder why?\")\n",
    "print(\"5. people with complaints are leaving a lot more, fix those issues asap!\")\n",
    "print(\"6. promo-only users bail when deals dry up, might need better regular pricing\")\n",
    "print(f\"7. {highest_region} folks churn more, maybe we need region-specific stuff\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
